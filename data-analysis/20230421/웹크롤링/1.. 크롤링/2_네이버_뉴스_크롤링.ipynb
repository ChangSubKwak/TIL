{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amim5qLVbjYZ"
      },
      "outputs": [],
      "source": [
        "# 구글 드라이브 마운트(드라이브 연결)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK7sC0zNb4-v"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/py_pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u12gksZccL9g"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QZqD38l8cNtA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "0             북풍 타고 내려온 황사, 주말 미세먼지 유의하세요\n",
            "1          황사 유입에 미세먼지 '매우나쁨'…낮 기온 14~25도\n",
            "2                오늘 또 전국에 황사…전국 미세먼지 ‘나쁨’\n",
            "3            황사에 미세먼지까지…“모레까지 맑은 하늘 못 본다”\n",
            "4      울릉도 미세먼지 '매우나쁨' 3배…경북 황사경보 '주의' 격상\n",
            "5       [오늘 날씨] 수도권 등 미세먼지 '나쁨'… 낮 최고 25도\n",
            "6     \"미세먼지 나빠요\"...오늘 맑지만 미세먼지 '나쁨~매우 나쁨'\n",
            "7                      평년 기온 회복…미세먼지 ‘나쁨’\n",
            "8    경북 미세먼지 '매우나쁨' 3.4배 치솟아…황사경보 '주의' 격상\n",
            "9                                미세먼지 때문에\n",
            "Name: 제목, dtype: object\n",
            "[8, 2, 6]\n"
          ]
        }
      ],
      "source": [
        "# 필요한 모듈 연경하기\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "import sys\n",
        "from xml.dom import minidom\n",
        "\n",
        "# 웹 크롤링 대상 URL \n",
        "# sch_txt=input('검색어 입력:')\n",
        "search_text = '미세먼지'\n",
        "url = \"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}\".format(search_text)\n",
        "\n",
        "# 네이버 코로나 검색 뉴스 페이지 소스정보 가져오기\n",
        "html_txt = requests.get(url)\n",
        "if html_txt.status_code != 200:\n",
        "  print(\"데이터를 가져오지 못했습니다.\")\n",
        "  sys.exit(0)    # 프로그램 강제 종료\n",
        "\n",
        "# soup = bs(html_txt.content, \"html.parser\")\n",
        "# 원하는 정보 가져오기, 1페이지 뉴스 정보 가져오기\n",
        "# soup_ul = soup.find('ul', class_=\"list_news\")\n",
        "#soup_ul\n",
        "#soup_div = soup_ul.find_all('div', class_=\"news_wrap api_ani_send\")\n",
        "\n",
        "# print(str(html_txt.content)[2:-1])\n",
        "# xmlraw = minidom.parseString(str(html_txt.content)[2:-1])\n",
        "# sentenceList = xmlraw.getElementsByTagName('ul') \n",
        "# print(sentenceList[0])\n",
        "\n",
        "soup_div = bs(html_txt.content, \"html.parser\")\\\n",
        "  .find('ul', class_ = \"list_news\")\\\n",
        "  .find_all('div', class_ = \"news_wrap api_ani_send\")\n",
        "\n",
        "print(len(soup_div))\n",
        "\n",
        "news_lst = []\n",
        "\n",
        "for div in soup_div:\n",
        "  info_txt = div.find('a',   class_ = \"info press\").get_text()\n",
        "  tit_txt  = div.find(\"a\",   class_ = \"news_tit\").get_text()\n",
        "  doc_txt  = div.find('div', class_ = \"news_dsc\").get_text()\n",
        "  news_lst.append({\n",
        "    \"제목\"   : tit_txt,\n",
        "    # \"제목\"   : tit_txt.split(\" \"),\n",
        "    \"내용\"   : doc_txt,\n",
        "    \"언론사\" : info_txt.replace('언론사 선정', \"\")\n",
        "  })\n",
        "\n",
        "news_df = pd.DataFrame(news_lst)\n",
        "# news_df['제목']\n",
        "\n",
        "print(news_df['제목'])\n",
        "\n",
        "find_words = ['나쁨', '기온', '황사']\n",
        "result = []\n",
        "for word in find_words:\n",
        "  count = 0\n",
        "  for info in news_df['제목']:\n",
        "    count += info.count(word) \n",
        "  result.append(count)\n",
        "\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIaBJ7n5sF9R"
      },
      "source": [
        "### 네이버 뉴스 페이지 지동 및 데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7rPVkpGiJ5p"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "# 웹 크롤링 대상 URL \n",
        "# 사용자 정의 함수 \n",
        "def url_request(sch_txt, page=1):\n",
        "    url=\"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=\" + str(sch_txt)\n",
        "    url=url+'&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=222&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start='+str(page )\n",
        "    # 네이버 코로나 검색 뉴스 페이지 소스정보 가져오기\n",
        "    html_txt=requests.get(url)     \n",
        "    if html_txt.status_code != 200:\n",
        "        print(\"데이터를 가져오지 못했습니다.\")\n",
        "        sys.exit(0)    # 프로그램 강제 종료\n",
        "\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++        \n",
        "news_lst=[]\n",
        "sch_txt=input('검색어 입력:')\n",
        "\n",
        "for page in range(1, 50, 10):\n",
        "    url_request(sch_txt, page)\n",
        "    soup=bs(html_txt.content, \"html.parser\")\n",
        "    # 원하는 정보 가져오기, 1페이지 뉴스 정보 가져오기\n",
        "    soup_ul=soup.find('ul', class_=\"list_news\")\n",
        "    #soup_ul\n",
        "    soup_div=soup_ul.find_all('div', class_=\"news_wrap api_ani_send\")\n",
        "    len(soup_div)\n",
        "\n",
        "    for div in soup_div:\n",
        "        info_txt=div.find('a', class_=\"info press\").get_text()\n",
        "        tit_txt=div.find(\"a\", class_=\"news_tit\").get_text()\n",
        "        doc_txt=div.find('div', class_=\"news_dsc\").get_text()\n",
        "        news_lst.append({\"제목\":tit_txt,\n",
        "                        \"내용\":doc_txt,\n",
        "                        \"언론사\":info_txt.replace('언론사 선정', \"\")})\n",
        "\n",
        "news_df=pd.DataFrame(news_lst)\n",
        "news_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsvsv4orte5o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "3. 네이버 뉴스 크롤링.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
